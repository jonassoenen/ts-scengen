{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Overall comparison\n",
    "Straight forward comparison between the two baselines (random, RLP) and the two proposed techniques expert-based and data-driven."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194690c-8f5c-4df7-a63d-b4caa6332bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from pathlib import Path\n",
    "\n",
    "# loading the data \n",
    "from scengen.data import generate_mockup_data\n",
    "\n",
    "# preprocessing the yearly info \n",
    "from scengen.preprocessing import YearlyInfoPreprocessor\n",
    "\n",
    "# sampling models \n",
    "from scengen.models.samplers import (RandomSampler, DailySamplerFromClusterSampler)\n",
    "from scengen.models.basesamplers import (ExpertDaySelectionSampler, MetadataClusterSampler, ConsumptionClusterSampler)\n",
    "from scengen.models.generators import RLPGenerator\n",
    "\n",
    "# clustering helpers\n",
    "from scengen.cluster.elbow import ElbowMethod\n",
    "import scengen.cluster.metrics as dist_metrics\n",
    "\n",
    "# clustering algorithms \n",
    "from sklearn.cluster import KMeans\n",
    "from kmedoids import KMedoids\n",
    "\n",
    "# classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# evaluation \n",
    "from scengen.evaluation import SamplerEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the mock-up data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04710ba2-9e97-4ec0-9bc5-0c9f8d18478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data_df, daily_data_df, yearly_info_df, daily_info_df = generate_mockup_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate folds for cross validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rand_gen = np.random.default_rng(12341243)\n",
    "folds = np.array_split(yearly_data_df.index, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models to compare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = dict()\n",
    "NB_SAMPLES = 250\n",
    "CLUSTER_RANGE = list(range(10, 101, 5))\n",
    "\n",
    "# random baseline\n",
    "models['random baseline'] = RandomSampler()\n",
    "\n",
    "# RLP/SLP baseline\n",
    "# this method needs to see the full dataset (both training and test set) in order to be able to assign the profiles to the correct RLP or SLP category.\n",
    "models['SLP baseline'] = RLPGenerator(yearly_data_df)\n",
    "\n",
    "# the expert-based technique\n",
    "# the expert-based technique with metadata clustering for year selection\n",
    "# and expert day selection for day selection\n",
    "models['expert-based'] = (\n",
    "    DailySamplerFromClusterSampler(\n",
    "        yearly_sampler=MetadataClusterSampler(\n",
    "            clusterer=ElbowMethod(KMeans(n_clusters=1, n_init=10), cluster_range=CLUSTER_RANGE),\n",
    "            info_preprocessing=YearlyInfoPreprocessor(columns_to_use=['yearly_consumption', 'connection_power'],\n",
    "                                                      normalized=True),\n",
    "        ),\n",
    "        daily_sampler=ExpertDaySelectionSampler()\n",
    "    )\n",
    ")\n",
    "\n",
    "# data-driven technique\n",
    "# the data driven approach with consumption clustering for both year and day selection\n",
    "models['data-driven'] = (\n",
    "    DailySamplerFromClusterSampler(\n",
    "        yearly_sampler=ConsumptionClusterSampler(\n",
    "            classifier=RandomForestClassifier(),\n",
    "            clusterer=ElbowMethod(KMedoids(n_clusters=1, method='fasterpam'),\n",
    "                                  metric=dist_metrics.euc_distance_matrix_missing, cluster_range=CLUSTER_RANGE,\n",
    "                                  nb_repeats=10),\n",
    "            fillna=False\n",
    "        ),\n",
    "        daily_sampler=ConsumptionClusterSampler(\n",
    "            classifier=RandomForestClassifier(),\n",
    "            clusterer=ElbowMethod(\n",
    "                clusterer=KMeans(n_clusters=1),\n",
    "                cluster_range=CLUSTER_RANGE,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure logging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843b9de-f32e-4fa5-8058-8093fe02b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s: %(message)s', level=logging.DEBUG,\n",
    "                    filename=f'{datetime.datetime.now().strftime(\"%d-%m-%Y\")}.log',\n",
    "                    filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50d5a9-859a-4b18-a890-2ded9b983eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "result_path = Path() / 'results' / 'overall_comparison'\n",
    "result_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "energy_scores = []\n",
    "evaluator = SamplerEvaluator(folds, yearly_data_df, daily_data_df, yearly_info_df, daily_info_df, None, 25,\n",
    "                             nb_samples=250, crossval=True)\n",
    "for key, model in list(models.items()):\n",
    "    energy_score = evaluator.evaluate_and_save(model, result_path / f\"{key}.pkl\")\n",
    "    energy_scores.append(energy_score)\n",
    "energy_scores = pd.concat(energy_scores, axis=1, keys=models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overall energy scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "energy_scores.mean(axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Per fold energy scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "means = []\n",
    "for fold in folds:\n",
    "    means.append(energy_scores.loc[fold].mean(axis=0))\n",
    "per_fold_ES = (\n",
    "    pd.concat(means, axis=1)\n",
    "    .stack()\n",
    "    .to_frame('ES')\n",
    "    .reset_index()\n",
    "    .assign(level_1=lambda x: x['level_1'].apply(lambda y: f\"fold {y + 1}\"))\n",
    ")\n",
    "per_fold_ES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a0af8-eb54-4280-b895-ab5748c921ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_std = pd.concat(means, axis=1).std(axis=1)\n",
    "fold_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
